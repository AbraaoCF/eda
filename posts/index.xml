
   <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
     <channel>
       <title>Posts on Estrutura de Dados</title>
       <link>https://joaoarthurbm.github.io/eda-ufcg-material/posts/</link>
       <description>Recent content in Posts on Estrutura de Dados</description>
       <generator>Hugo -- gohugo.io</generator>
       <copyright>Copyright &amp;copy; 2019 - João Arthur Brunet</copyright>
       <lastBuildDate>Tue, 01 Oct 2019 00:00:00 -0300</lastBuildDate>
       
           <atom:link href="https://joaoarthurbm.github.io/eda-ufcg-material/posts/index.xml" rel="self" type="application/rss+xml" />
       
       
       <item>
         <title>Introdução à Análise de Algoritmos</title>
         <link>https://joaoarthurbm.github.io/eda-ufcg-material/posts/introducao-a-analise/</link>
         <pubDate>Tue, 01 Oct 2019 00:00:00 -0300</pubDate>
         
         <guid>https://joaoarthurbm.github.io/eda-ufcg-material/posts/introducao-a-analise/</guid>
         <description>

&lt;hr /&gt;

&lt;h2 id=&#34;contextualização&#34;&gt;Contextualização&lt;/h2&gt;

&lt;p&gt;A análise de eficiência é uma etapa fundamental na concepção de um algoritmo. Embora aspectos como legibilidade, simplicidade e modularidade de uma solução sejam importantes para a sua manutenabilidade, a eficiência de uma solução desempenha um papel muito relevante para a sua adoção.&lt;/p&gt;

&lt;p&gt;Diante de um problema computacional, diversas soluções podem ser propostas. Por exemplo, para ordenar um sequência de números, o desenvolvedor pode utilizar algoritmos como o BubbleSort, MergeSort, QuickSort entre outros. Entender como esses algoritmos se comportam à medida que aumentamos o tamanho da entrada a ser ordenada é primordial para decidirmos qual solução adotar em um determinado contexto.&lt;/p&gt;

&lt;p&gt;Analisar um algoritmo significa prever a quantidade de recursos que tal algoritmo consome ao ser executado. A análise pode apontar diversos candidatos e, tipicamente, exclui diversas soluções não eficientes. Diversas variáveis podem ser objetos de estudo da análise de um algoritmo, por exemplo, consumo de memória, largura de banda de comunicação entre outros. No entanto, com frequência, desejamos medir o tempo execução. E é essa variável que estamos interessados em discutir neste documento.&lt;/p&gt;

&lt;p&gt;Uma abordagem direta para analisar o desempenho de um algoritmo é a abordagem empírica. Neste caso, configura-se um ambiente em que as variáveis são controladas e executa-se os algoritmos com o intuito de medir o tempo de computação e comparar as diferentes soluções.
O tempo de execução (eixo y) é medido em função do tamanho da entrada (eixo x). Por exemplo, para analisar empiricamente um algoritmo de ordenação medimos o tempo de execução para diferentes tamanhos de arrays. Além disso, podemos querer variar a configuração do array sob ordenação, isto é, como o algoritmo se comporta com um array já ordenado? Como se comporta com arrays parcialmente ordenados?&lt;/p&gt;

&lt;p&gt;Tipicamente, executa-se um experimento com o tamanho da amostra suficiente para se ter validade estatística e permitir a construção de um modelo que represente a curva de cada algoritmo. A Figura abaixo, por exemplo, apresenta os tempos de computação de diferentes algoritmos à medida que aumenta-se o tamanho da entrada. Como podemos notar, o algoritmo SelectionSort apresenta tempo de execução consideravelmente maior em comparação com as outras três alternativas à medida que a quantidade de elementos a serem ordenados cresce.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;comparacao-ordenacao.jpeg&#34; alt=&#34;comp-ordenacao&#34; title=&#34;Comparação de Algoritmos de Ordenação&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A abordagem empírica para análise de algoritmos é útil, pois, se conduzida de maneira metodologicamente apropriada, fornece valores precisos sobre o tempo de execução de um algoritmo. No entanto, essa abordagem apresenta algumas desvantagens. Primeiro, existe um alto custo relacionado à implementação de todos os algoritmos, além da configuração, execução e análise do experimento. Além disso, note que as conclusões são limitadas ao espaço de entrada do experimento. Por fim, os resultados são dependentes do hardware utilizado.&lt;/p&gt;

&lt;p&gt;Diante do cenário exposto acima, surge a necessidade de uma análise que:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;seja independente de hardware&lt;/li&gt;
&lt;li&gt;permita analisar os algoritmos em um espectro maior de entradas&lt;/li&gt;
&lt;li&gt;seja simples&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note que, em diversas situações, o interesse está em comparar algoritmos, ao invés de determinar o seu tempo exato de execução. Em particular, &lt;strong&gt;estamos interessados nas funções no comportamento dos algoritmos para grandes tamanhos de entrada &amp;ndash; análise assintótica.&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;análise-de-algoritmos&#34;&gt;Análise de Algoritmos&lt;/h2&gt;

&lt;p&gt;Antes de apresentar os conceitos de análise assintótica, sua notação e modus operandi, é preciso apresentar a hipótese em que a análise se baseia:&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;Hipótese: O custo de operações primitivas é constante.&lt;/p&gt;

&lt;p&gt;Essa hipótese estabelece que operações aritméticas, indexação de elementos em um vetor, retorno de métodos / funções, atribuição de valores às variáveis, comparação de elementos, entre outros, executam em tempo constante, referenciado como&lt;/p&gt;

&lt;p&gt;$O(1)$ ou $O(C)$. É importante destacar que, na prática, esse custo varia de acordo com o hardware, linguagem de programação etc. No entanto, essa variação é insignificante do ponto de vista da análise assintótica. O quadro abaixo lista as operações primitivas detalhadamente.&lt;/p&gt;

&lt;pre&gt;
Operações Primitivas

* Avaliação de expressões booleanas (i &gt;= 2; i == 2, etc);

* Operações matemáticas (*, -, +, %, etc);

* Retorno de métodos (return x;);

* Atribuição (i = 2);

* Acesso à variáveis e posições arbitrárias de um array (v[i]).

&lt;/pre&gt;

&lt;p&gt;Nesse contexto, o tempo de execução de um algoritmo é a soma do custo das operações primitivas. Por exemplo, considere o algoritmo que multiplica o resto da divisão de dois inteiros pela parte inteira da mesma divisão:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;multiplicaRestoPorParteInteira&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;j&lt;/span&gt;) {
    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;resto&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; j;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pInteira&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; j;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;resultado&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; resto &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; pInteira;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; resultado;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Passo 1: Identificar primitivas.&lt;/strong&gt; O primeiro passo para determinar de modo analítico o tempo de execução de qualquer algoritmo é identificar todas as operações primitivas. Cada uma, como discutido anteriormente, tem um custo constante. Para o algoritmo acima temos:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;atribuição (resto = ) -&amp;gt; $c1$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;operação aritmética (i % j) -&amp;gt; $c2$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;atribuição (pInteira = ) -&amp;gt; $c3$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;operação aritmética (i % j) -&amp;gt; $c4$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;atribuição (resultado = ) -&amp;gt; $c5$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;operação aritmética (resto * pInteira) -&amp;gt; $c6$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;retorno de método (return resultado) -&amp;gt; $c7$&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Passo 2: Identificar a quantidade de vezes que cada uma das primitivas é executada.&lt;/strong&gt; Para o algoritmo acima, todas as primitivas são executadas apenas uma vez.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Passo 3: Somar o custo total.&lt;/strong&gt; O tempo de execução do algoritmo é a soma das execuções das operações primitivas. Nesse caso temos que a função que descreve o tempo de execução é:&lt;/p&gt;

&lt;p&gt;$f(n) = c1+c2+c3+c4+c5+c6+c7$&lt;/p&gt;

&lt;p&gt;Lembrando estamos interessados em uma função que nos diga o tempo de execução em relação ao tamanho da entrada. Nesse caso, escolhemos $n$ para representar o tamanho da entrada. Como pode ser visto na função detalhada, o custo não depende de $n$ de maneira alguma. Independente os números passados como parâmetro, o custo será sempre o mesmo. Por isso dizemos que essa função, e portanto o algoritmo que é descrito por ela, tem &lt;strong&gt;custo constante&lt;/strong&gt;, ou seja, independe do tamanho da entrada.&lt;/p&gt;

&lt;p&gt;Outro fator de destaque é que podemos considerar que todas as constantes possuem o mesmo valor $c$. Assim, podemos simplificar a função para $f(n)= 7c$.&lt;/p&gt;

&lt;h3 id=&#34;e-quando-houver-condicionais&#34;&gt;E quando houver condicionais?&lt;/h3&gt;

&lt;p&gt;O uso de comandos condicionais é muito comum em nossos algoritmos e nos impõe uma dificuldade na análise do tempo de execução. Essa dificuldade está relacionada ao fato de que, dependendo do caso, apenas uma parte do código é executada. Como decidir como fazer a análise? Que caminho devemos computar?&lt;/p&gt;

&lt;p&gt;Nesse caso, escolhemos &lt;strong&gt;o pior caso&lt;/strong&gt;. Neste curso estamos interessados em saber como os algoritmos se comportam no seu pior caso. A análise do pior caso é útil para eliminarmos soluções ruins. Além disso, o melhor caso raramente acontece, ao contrário dos outros casos que podem ser bem mais comuns. Por último, o caso médio, além de demandar análise estatística, muitas vezes é muito semelhante ao pior caso.&lt;/p&gt;

&lt;p&gt;Por ora, vamos analisar um método que recebe as três notas de um aluno e calcula a nota que ele precisa obter na prova final, se esse for o caso. Se o aluno for aprovado ($media &amp;gt;= 7.0$) ou reprovado sem direito a final ($media &amp;lt; 4$), o método deve retornar $0$.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;precisaNaFinal&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;nota1&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;nota2&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;nota3&lt;/span&gt;) {

    &lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;media&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (nota1 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; nota2 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; nota3) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; 3;
        
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (media &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; 7 &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt; media &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; 4) {
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; 0;
        
    } &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; {
        &lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mediaFinal&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 5;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pesoFinal&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 0.&lt;span style=&#34;color:#a6e22e&#34;&gt;4&lt;/span&gt;;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pesoMedia&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 0.&lt;span style=&#34;color:#a6e22e&#34;&gt;6&lt;/span&gt;;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;precisa&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (mediaFinal &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; pesoMedia &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; media) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; pesoFinal;
            
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; precisa;
    }

}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Passo 1. Identificar primitivas.&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;atribuição (media = ) -&amp;gt; $c1$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;operação aritmética (nota1 + nota2 + nota3) -&amp;gt; $c2$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;operação aritmética (&amp;hellip; / 3) -&amp;gt; $c3$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;avaliação de expressão booleana (media &amp;gt;=7 || media &amp;lt; 4) -&amp;gt; $c4$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;retorno de método (return 0) -&amp;gt; $c5$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;atribuição (mediaFinal = ) -&amp;gt; $c6$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;atribuição (pesoFinal = ) -&amp;gt; $c7$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;atribuição (pesoMedia = ) -&amp;gt; $c8$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;atribuição (precisa = ) -&amp;gt; $c9$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;operação aritmética (pesoMedia * media) -&amp;gt; $c10$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;operação aritmética (mediaFinal -  &amp;hellip;) -&amp;gt; $c11$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;operação aritmética (&amp;hellip; / pesoFinal) -&amp;gt; $c12$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;retorno de método (return precisa) -&amp;gt; $c13$&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Passo 2: Identificar a quantidade de vezes que cada uma das primitivas é executada.&lt;/strong&gt; Aqui vem a grande diferença. Como estamos interessados no pior caso, nós vamos descartar a constante c5 pois, no pior caso, o bloco do else será executado, pois é mais custosa que o bloco do if. As outras primitivas são executadas apenas uma vez.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Passo 3: Somar o custo total.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$f(n) = c1+c2+c3+c4+c6+c7+c8+c9+c10+c11+c12+c13$&lt;/p&gt;

&lt;h3 id=&#34;e-quando-houver-iteração&#34;&gt;E quando houver iteração?&lt;/h3&gt;

&lt;p&gt;Nos dois exemplos que vimos até aqui todas as primitivas são executadas apenas uma vez e, por isso, o tempo de execução do algoritmo é sempre constante. Vejamos o que acontece quando há iteração. O código abaixo procura por um elemento em um array.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;static&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;boolean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;contains&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;[] &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;n&lt;/span&gt;) {
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 0; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; v.&lt;span style=&#34;color:#a6e22e&#34;&gt;length&lt;/span&gt;; i&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (v[i] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; n)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Passo 1: Identificar primitivas.&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Atribuição (int i = 0) -&amp;gt; $c1$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Avaliação de expressão booleana (i &amp;lt; v.length) -&amp;gt; $c2$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Operação aritmética (i++) -&amp;gt; $c3$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Avaliação de expressão booleana (v[i] == n) -&amp;gt; $c4$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Retorno de método (return true) -&amp;gt; $c5$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Retorno de método (return false) -&amp;gt; $c6$&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Passo 2: Identificar a quantidade de vezes que cada uma das primitivas é executada.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Aqui mora a grande diferença da análise deste exemplo em relação aos demais. Em primeiro lugar, nem todas as primitivas são executadas apenas uma vez. Depois, temos que voltar a lembrar que estamos tratando do pior caso. Esse cenário é representado por um array que não contém o número procurado, pois o algoritmo irá realizar todas as iterações e retornar false no final. Veja que se o número estiver dentro do array, a execução pode terminar bem antes do fim da iteração no array. Isso significa que, na nossa análise, vamos descartar a primitiva $c5$, pois no pior caso ela nunca é executada.&lt;/p&gt;

&lt;p&gt;Dado que o tamanho do vetor (v.length) é $n$, temos:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;$c1$ é executada apenas uma vez.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$c2$ é executada $(n+1)$ vezes. Exemplo: se $n = 5$, temos as seguintes verificações: 0 &amp;lt; 5, 1 &amp;lt; 5; 2 &amp;lt; 5, 3 &amp;lt; 5, 4 &amp;lt; 5 e 5 &amp;lt; 5, quando encerra-se o loop. Ou seja, 6 verificações.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$c3$ é executada $n$ vezes. Exemplo: se $n = 5$, temos os seguintes incrementos em i: 1, 2, 3, 4 e 5, quando encerra-se o loop.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$c4$ é executada $n$ vezes.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;No pior caso, $c5$ não é executada.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$c6$ é executada apenas uma vez.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Passo 3: Somar o custo total.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;O tempo de execução do algoritmo é a soma das execuções das operações primitivas. Nesse caso temos que a função que descreve o tempo de execução é:&lt;/p&gt;

&lt;p&gt;$f(n) = c1+c2*(n+1)+c3*n+c4*n+c6$, considerando todas as primitivas com custo $c$ e simplificando a função, temos:&lt;/p&gt;

&lt;p&gt;$f(n) = 3*c*n+3*c$&lt;/p&gt;

&lt;p&gt;Veja que essa função é diretamente relacionada ao tamanho do array ($n$). A medida que cresce o tamanho de $n$, cresce também o tempo de execução do pior caso. Esse crescimento é linear, pois a função é linear. Faz sentido, certo? Iterar em um array com 100 posições é 10 vezes mais lento que iterar em um array de 10 posições.&lt;/p&gt;

&lt;p&gt;Vamos ver mais um exemplo.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;boolean&lt;/span&gt; contemDuplicacao(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;[] &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;) {
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 0; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; v.&lt;span style=&#34;color:#a6e22e&#34;&gt;length&lt;/span&gt;; i&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;j&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 1; j &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; v.&lt;span style=&#34;color:#a6e22e&#34;&gt;length&lt;/span&gt;; j&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (v[i] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; v[j])
                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Passo 1: Identificar primitivas.&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Atribuição (int i = 0) -&amp;gt; c1&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Avaliação de expressão booleana (i &amp;lt; v.length) -&amp;gt; c2&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Operação aritmética (i++) -&amp;gt; c3&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Atribuição (int j = i + 1) -&amp;gt; c4&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Avaliação de expressão booleana (j &amp;lt; v.length) -&amp;gt; c5&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Operação aritmética (j++) -&amp;gt; c6&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Avaliação de expressão booleana (v[i] == v[j]) -&amp;gt; c7&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Retorno de método (return true) -&amp;gt; c8&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Retorno de método (return false) -&amp;gt; c9&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Passo 2: Identificar a quantidade de vezes que cada uma das primitivas é executada.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;O pior caso de execução desse algoritmo é quando não há repetição de valores no array. Ou seja, os loops são executados até o final. Então, como estamos falando do pior caso, descartamos $c8$, porque no pior caso essa primitiva nunca será executada.&lt;/p&gt;

&lt;p&gt;Dado que o tamanho do vetor (v.length) é $n$, temos:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;$c1$ é executada apenas uma vez.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$c2$ é executada $(n+1)$ vezes. Exemplo: se $n = 5$, temos as seguintes verificações: 0 &amp;lt; 5, 1 &amp;lt; 5; 2 &amp;lt; 5, 3 &amp;lt; 5, 4 &amp;lt; 5 e 5 &amp;lt; 5, quando encerra-se o loop. Ou seja, 6 verificações.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$c3$ é executada $n$ vezes. Exemplo: se $n = 5$, temos os seguintes incrementos em i: 1, 2, 3, 4 e 5, quando encerra-se o loop.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Agora, atenção, porque vamos tratar das primitivas do laço mais interno.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A quantidade de vezes que $c4$ é executada depende do laço mais externo, pois $j$ varia de acordo com $i$ ($j = i+1$). Como o laço externo executa $n$ vezes, a quantidade de vezes que $j$ varia é dada por: $(n - 1) + (n - 2) + (n - 3) + (n-4) + &amp;hellip;1$. Essa série representa uma Progressão Aritmética finita decrescente com razão 1. A soma de uma PA com essas características é dada por $S = n/2 * (a1+an)$, onde $a1$ e $an$ são o primeiro e o último elemento da sequência, respectivamente. Assim, para $a1=1$ e $an = n-1$, temos que $c4$ é executada ${n^2}/{2}$ vezes.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Como $c5$ é executada uma vez a mais que $c4$ por causa do último teste para sair do laço, então temos que o primeiro termo da PA é $a1 = 1$ e $an = n$. Assim, temos que $c5$ é executada $({n^2 + n})/{2}$.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$c6$ e $c7$ são executadas a mesma quantidade de vezes que $c4$.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$c8$ não é executada nenhuma vez porque estamos falando do pior caso&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$c9$ é executada apenas uma vez.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Passo 3: Somar o custo total.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;O tempo de execução do algoritmo é a soma das execuções das operações primitivas. Nesse caso temos que a função que descreve o tempo de execução é:&lt;/p&gt;

&lt;p&gt;$f(n) = c1 + c2*(n+1) + c3*n + c4 * {n^2}/2 + c5 * (n^2 + n)/2 + c6 * {n^2}/2 + c7 * {n^2}/2 + c9$,&lt;/p&gt;

&lt;p&gt;considerando todas as primitivas com custo c e simplificando a função, temos:&lt;/p&gt;

&lt;p&gt;$f(n) = 3 * c + 2 * c * n + 3 * {n^2}/2 + c * (n^2 + n)/2$&lt;/p&gt;

&lt;p&gt;Veja que essa função é diretamente relacionada ao tamanho do array (n). A medida que cresce o tamanho de $n$, cresce também o tempo de execução do pior caso. O tempo de execução do algoritmo cresce de forma quadrática em relação ao tamanho da entrada, pois a função é quadrática. Faz sentido, certo? Comparar cada elemento de um array com todos os outros é da ordem de $n^2$.&lt;/p&gt;

&lt;p&gt;É importante que você entenda que esse algoritmo é bem mais lento do que o anterior, pois uma função quadrática cresce mais rapidamente que uma função linear.&lt;/p&gt;

&lt;p&gt;No material sobre &lt;a href=&#34;http://joaoarthurbm.github.io/eda-ufcg-material/posts/analise-assintotica&#34;&gt;Análise Assintótica&lt;/a&gt; vamos aprender que essa função complicada pode ser simplificada para $n^2$ quando tratamos de grandes entradas, pois as constantes e os expoentes de menor magnitude não impactam muito nesse cenário.&lt;/p&gt;

&lt;h2 id=&#34;resumo&#34;&gt;Resumo&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Calcular o tempo de execução de um algoritmo é muito importante.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Uma forma de calcular o tempo de execução é seguir os passos:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Identificar primitivas&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Identificar o número de vezes que cada uma das primitivas é executada&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Somar o custo total&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;É preciso estar atento para o fato de que estamos falando de análise do pior caso e, por isso, descartamos os fluxos alternativos de menor custo.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
       </item>
       
       <item>
         <title>Análise Assintótica</title>
         <link>https://joaoarthurbm.github.io/eda-ufcg-material/posts/analise-assintotica/</link>
         <pubDate>Sun, 29 Sep 2019 00:00:00 -0300</pubDate>
         
         <guid>https://joaoarthurbm.github.io/eda-ufcg-material/posts/analise-assintotica/</guid>
         <description>

&lt;hr /&gt;

&lt;h1 id=&#34;contextualização&#34;&gt;Contextualização&lt;/h1&gt;

&lt;p&gt;Quando observamos tamanhos de entrada grande o suficiente para tornar relevante apenas a ordem de crescimento do tempo de execução, estamos estudando a eficiência assintótica.&lt;/p&gt;

&lt;p&gt;No &lt;a href=&#34;https://joaoarthurbm.github.io/eda-ufcg-material/posts/introducao-a-analise/&#34;&gt;material introdutório&lt;/a&gt; sobre análise de algoritmos, aplicando as diretrizes de simplificação, aprendemos que funções complexas podem ser mapeadas para classes de funções sobre as quais conhecemos o crescimento ($n$, $\log n$, $n^2$ etc). Para ilustrar esse mapeamento utilizamos a notação $\Theta$. Chegou a hora de entendermos o que essa notação significa.&lt;/p&gt;

&lt;p&gt;Primeiro, preciso deixar claro que cometi alguns abusos matemáticos para fins didáticos. Vamos relembrar esses abusos e explicá-los um a um.&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;$2*n + 1 = \Theta(n)$&lt;/p&gt;

&lt;p&gt;Theta ($\Theta$) é um conjunto de funções. Nesse caso, o conjunto das funções lineares. Por isso, é um abuso dizer que $2*n + 1$ é $\Theta(n)$. A maneira formal de dizer é: $2*n + 1$ &lt;strong&gt;pertence&lt;/strong&gt; a $\Theta(n)$.&lt;/p&gt;

&lt;p&gt;Além disso, poderíamos ter escolhido qualquer função linear para dizer que $2 * n + 1$ tem a mesma ordem de crescimento. Nós escolhemos $n$ porque é a mais simples.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;a-notação-theta&#34;&gt;A notação $\Theta$&lt;/h1&gt;

&lt;p&gt;Agora vamos definir formalmente o que significa essa notação. Para duas funções $f(n)$ e $g(n)$, dizemos que $f(n)$ é $\Theta(g(n))$ se&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;$0&lt;=c1*g(n)&lt;= f(n)&lt;= c2*g(n), \forall n&gt;=n0$&lt;/p&gt;

&lt;p&gt;Vamos entender o que essa inequação complicada quer nos dizer. Em um resumo bem simplista ela está dizendo que se a gente &amp;ldquo;imprensar&amp;rdquo; $f(n)$ com $g(n)$ multiplicada por duas constantes diferentes, dizemos que $f(n)$ é $\Theta(g(n))$.&lt;/p&gt;

&lt;p&gt;Vamos ao exemplo. Lembra da função que descreve o tempo de execução da busca linear? Vamos tentar mostrar que essa função é $\Theta(n)$.&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;$f(n) = 3*c*n+3*c$&lt;/p&gt;

&lt;p&gt;O primeiro passo que vamos fazer é trocar as constantes por 1. Isso já foi dito antes. Usar $c$ ou 1 tem o mesmo efeito. Assim, temos:&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;$f(n) = 3n+3$&lt;/p&gt; 

&lt;p&gt;Agora vamos voltar a inequação. Como &amp;ldquo;desconfiamos&amp;rdquo; que $f(n) = 3n+3$ é $\Theta(n), escolhemos $g(n)=n$. Poderíamos escolher qualquer função linear para representar $g(n)$, escolhemos a função linear mais simples para facilitar nossa vida. Assim, a inequação fica:&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;$0&lt;=c1*n&lt;= 3n+3&lt;= c2*n, \forall n&gt;=n0$&lt;/p&gt;  

&lt;p&gt;Agora precisamos encontrar valores para $c1$ e $c2$ para que essa inequação seja verdadeira. Vamos tentar com c1=1 e c2=6.&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;$0&lt;=n&lt;= 3n+3&lt;= 6*n, \forall n&gt;=n0$&lt;/p&gt;  

&lt;p&gt;Se verificarmos com $n=1$, vemos que a inequação é verdadeira:&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;$0&lt;=1&lt;= 6&lt;= 6$&lt;/p&gt;  

&lt;p&gt;Não é difícil também notar que $\forall n &amp;gt; 1$ ela sempre será verdadeira. Conseguimos, então, demonstrar que $f(n) \in \Theta(n)$, pois $g(n)=n$ limita inferior e superiomente $f(n)$.&lt;/p&gt;

&lt;p&gt;Na verdade, todas as funções lineares são limitadas inferior e superiormente por $n$. No nosso linguajar, podemos dizer que todas as funções abaixo pertencem a $\Theta(n)$.&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;$7*n, 827643*n, 5n+21, 54n +1...$&lt;/p&gt;  

&lt;p&gt;Formalmente dizemos que $g(n)=n$ é um limite assintótico restrito para $f(n)$. A figura abaixo descreve essa relação entre uma função quadrática e as funções $3n$ e $n^2$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;theta.png&#34; alt=&#34;theta&#34; width=&#34;1px&#34; height=&#34;320px&#34;/&gt;&lt;/p&gt;

&lt;p&gt;Em português estamos dizendo que existe, para grandes valores de $n$ e a partir de um número inteiro positivo $n0$, $c1$ e $c2$ tais que $c1*g(n)&amp;lt;= f(n)&amp;lt;= c2*g(n)$.&lt;/p&gt;

&lt;pre&gt;
Em termos mais simplistas estamos dizendo que o crescimento de 
f(n) é igual ao de g(n).
&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Outro exemplo.&lt;/strong&gt; Suponha a função $7 * n^4 + 5 * n^2 +10$ que descreve o custo de execução de um algoritmo. Se aplicarmos as abstrações simplificadoras, desconfiamos que $f(n) \in \Theta(n4)$, certo? Vamos demonstrar formalmente.&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;$0 &lt;= c1 * n^4 &lt;= 7 * n^4 + 5 * n^2 + 10 &lt;= c2*n4, \forall n &gt;= n0$&lt;/p&gt;  

&lt;p&gt;Se escolhermos $c1=7$, $c2=22$ e $n0=1$, temos:&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt; $ 0 &lt;=7 &lt;= 22 &lt;= 22 $&lt;/p&gt;

&lt;p&gt;Na verdade, todas as funções quadráticas são limitadas inferior e superiormente por $n^2$. No nosso linguajar, podemos dizer que todas as funções abaixo pertencem a $\Theta(n^2)$.&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt; $ 43 * n^2 + 7n + 1, 5 * n^2 + 21, 7 * n^2...$ &lt;p&gt;

Em resumo, para demonstrar formalmente precisamos dos seguintes passos:

1. Aplicar as abstrações simplificadores em $f(n)$ para termos uma proposta para $g(n)$.

2. Encontrar valores de $c1$, $c2$ e $n0$ para os quais a inequação $0&lt;=c1*g(n)&lt;= f(n)&lt;= c2*g(n)$ é verdadeira. 

Há mais 4(!) notações para estabelecer a relação entre funções. Neste material vamos ver apenas mais duas porque considero que é suficiente. Independente disso, todas são nada mais do que alterações na inequação que estabelecemos para $\Theta$. Por exemplo, a próxima notação que veremos, provavelmente a mais popular de todas, nada mais é do que retirar o limite inferior da inequação e apenas estabelecer um limite superior.

*** 

# Notação O (Big O notation)

Enquanto a notação $\Theta$ define os limites inferior e superior de uma função, a notação $O$ define apenas o limite superior. Ou seja, define um teto para uma determinada função. 

Para duas funções $f(n)$ e $g(n)$, dizemos que $f(n)$ é $O(g(n))$ se: 

&lt;p align=&#34;center&#34;&gt; $0&lt;=f(n)&lt;= c*g(n), \forall n&gt;=n0$ &lt;/p&gt;

&lt;p&gt;Veja que a diferença entre essa inequação e a utilizada para a notação é o fato de que aqui o limite inferior é 0 e não $c1 * g(n)$. A figura abaixo ilustra essa relação.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;bigo.png&#34; alt=&#34;bigo&#34; /&gt;&lt;/p&gt;

&lt;p&gt;O processo para demonstrar que $f(n)$ é $O(g(n))$ é muito semelhante, mas nesse caso precisamos achar apenas os valores de $c$ e $n0$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Exemplo.&lt;/strong&gt; Suponha que a função $n^2 + 1$ descreve o custo de execução de um algoritmo. Se aplicarmos as abstrações simplificadoras, desconfiamos que $f(n) \in O(n^2)$, certo? Vamos demonstrar formalmente.&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt; $0 &lt;= n^2 + 1 &lt;= c * n^2, \forall n&gt;=n0$ &lt;/p&gt;

&lt;p&gt;Se escolhermos c1=1 e n0=1, temos:&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt; $1 &lt;= 1$ &lt;/p&gt;

&lt;p&gt;Como você pode perceber, toda função que pertence a $\Theta(n^2)$ também pertence a $O(n^2)$, porque limita também superiormente como $O$.Contudo, nem toda função que pertence a $O(n^2)$, por exemplo, também pertence a $\Theta(n)$, pois $O$ estabelece apenas o limite superior. Por exemplo, a função $f(n) = 7$ é limitada superiormente por $n^2$, portanto é $O(n^2)$. Contudo, não podemos dizer que ela é $\Theta(n^2)$ porque não há constante multiplicadora que para n suficientemente grande faça com que $c1 * n^2$ seja menor do que $7n$.&lt;/p&gt;

&lt;p&gt;Simples, não é? A notação $O$ é bastante utilizada em Computação para discutir a eficiência de algoritmos. E há aqui uma curiosidade. Como discutido no parágrafo anterior, basta escolhermos uma função com $n$ elevado a um expoente maior do que o da função sob análise que conseguimos definir um limite superior para ele. Por exemplo, a função $f(n) = n^2$ é $O(n^2)$, $O(n^3)$, $O(n^4)$, e assim por diante.  Todavia, faz mais sentido escolhermos uma função com o mesmo expoente, porque a informação é mais precisa. Ou seja, se uma função é quadrática, dizemos que ela é $O(n^2)$.&lt;/p&gt;

&lt;p&gt;Por fim, outra particularidade dessa notação é que usamos com muita frequência nas discussões do a dia a notação $O$ ao invés da notação $\Theta$. Talvez porque seja mais fácil de falar $O$ do que theta e, como somos preguiçosos, tendemos a economizar energia até na fala. Mas é relevante destacar que, tipicamente, a semântica que queremos empregar nas discussões com o uso da notação $O$ é a mesma de $\Theta$.&lt;/p&gt;

&lt;pre&gt;
Em termos mais simplistas estamos dizendo que o crescimento de 
f(n) é menor ou igual ao crescimento de g(n).
&lt;/pre&gt;

&lt;h1 id=&#34;notação-omega-omega&#34;&gt;Notação Omega ($\Omega$)&lt;/h1&gt;
</description>
       </item>
       
     </channel>
   </rss>
